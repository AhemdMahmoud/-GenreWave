# -*- coding: utf-8 -*-
"""Fn_Audio_music_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vaxY4J2qUZiVOup_dYmBOuT8qw0MFtij
"""

# ! pip install datasets
# ! pip install gradio

from datasets import load_dataset

gtzan = load_dataset("marsyas/gtzan", "all")
gtzan

gtzan = gtzan["train"].train_test_split(seed=42, shuffle=True, test_size=0.2)
gtzan

gtzan["train"][0]

id2label_fn = gtzan["train"].features["genre"].int2str
id2label_fn(gtzan["train"][0]["genre"])

# import gradio as gr


# def generate_audio():
#     example = gtzan["train"].shuffle()[0]
#     audio = example["audio"]
#     return (
#         audio["sampling_rate"],
#         audio["array"],
#     ), id2label_fn(example["genre"])


# with gr.Blocks() as demo:
#     with gr.Column():
#         for _ in range(4):
#             audio, label = generate_audio()
#             output = gr.Audio(audio, label=label)

# demo.launch(debug=True)

"""# Preprocessing the data"""

from transformers import AutoFeatureExtractor

model_id = "ntu-spml/distilhubert"

feature_extractor = AutoFeatureExtractor.from_pretrained(
    model_id,
    do_normalize=True,
    return_attention_mask=True,

)

sampleing_rate = feature_extractor.sampling_rate
sampleing_rate

"""## sampling rate for feature_extractor is 16000 but for trained data is  'sampling_rate': 22050}

# Resample
"""

from datasets import Audio

gtzan = gtzan.cast_column("audio",Audio(sampling_rate=16000))

gtzan["train"][0]

"""# it's changed

### For our model to work optimally, we want to keep all the inputs within the same dynamic range. This is going to make sure we get a similar range of activations and gradients for our samples, helping with stability and convergence during training.

### To do this, we normalise our audio data, by rescaling each sample to zero mean and unit variance, a process called feature scaling.
"""

import numpy as np

sample = gtzan["train"][0]["audio"]

print (f"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}")

inputs = feature_extractor(sample["array"], sampling_rate=sample["sampling_rate"])

inputs

print (f"inputs keys: {list(inputs.keys())}")

print (f"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}")

max_duration = 30.0

def process_audio(example):
  audio_array = [x["array"] for x in example["audio"] ]
  inputs = feature_extractor(
      audio_array,
      sampling_rate = feature_extractor.sampling_rate,
      max_length = int(feature_extractor.sampling_rate * max_duration),
      truncatation = True,
      return_attention_mask = True,

  )
  return inputs

gtzan_encoded = gtzan.map(process_audio,batched=True, batch_size=100, remove_columns=["audio", "file"], num_proc=1)

gtzan_encoded

gtzan_encoded = gtzan_encoded.rename_column("genre", "label")

id2label = {
     str(i): id2label_fn(i) for i, label in enumerate(list(set(gtzan_encoded["train"]["label"])))
}

label2id = {v: k for k, v in id2label.items()}

print(f"id2label: {id2label}")
print(f"label2id: {label2id}")

id2label["9"]

"""# Fine-tuning the model"""

from transformers import AutoModelForAudioClassification

model = AutoModelForAudioClassification.from_pretrained(
    model_id,
    num_labels=len(id2label),
    label2id=label2id,
    id2label=id2label,
)

from huggingface_hub import notebook_login

notebook_login()

from transformers import TrainingArguments

model_id

import transformers
print(transformers.__version__)

# !pip uninstall transformers
# !pip install transformers

from transformers import TrainingArguments

training_args = TrainingArguments(
    f"{model_id.split('/')[-1]}-finetuned-gtzan",
    do_eval=True,
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    gradient_accumulation_steps=1,
    per_device_eval_batch_size=4,
    num_train_epochs=12,
    warmup_ratio=0.1,
    logging_steps=5,
    # load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    fp16=True,
    push_to_hub=True,
)

! pip install evaluate

import evaluate
import numpy as np

metric = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    """Computes accuracy on a batch of predictions"""
    predictions = np.argmax(eval_pred.predictions,axis=1)
    return metric.compute(predictions=predictions, references=eval_pred.label_ids)

! pip install --upgrade wandb

import os
os.environ["WANDB_DISABLED"] = "true"

! wandb offline

from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=gtzan_encoded["train"],
    eval_dataset=gtzan_encoded["test"],
    tokenizer=feature_extractor,
    compute_metrics=compute_metrics,
)

trainer.train()

kwargs = {
    "dataset_tags": "marsyas/gtzan",
    "dataset": "GTZAN",
    "model_name": f"{model_id.split("/")[-1]}-finetuned-gtzan",
    "finetuned_from": model_id,
    "tasks": "audio-classification",
}

trainer.push_to_hub(**kwargs)



